{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"authorship_tag":"ABX9TyOZT5tWE08SkegDyGVsBHl+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Khnpa4NRmIA","executionInfo":{"status":"ok","timestamp":1608692978936,"user_tz":-420,"elapsed":1956,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"dc4d35f6-0504-403f-d9c4-76bf7c99fead"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RDZQxj_GRz0q","executionInfo":{"status":"ok","timestamp":1608697624434,"user_tz":-420,"elapsed":1160,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Importing library\r\n","import numpy as np\r\n","import pandas as pd\r\n","\r\n","# BeautifulSoup = hapus tag html\r\n","from bs4 import BeautifulSoup \r\n","import re # regular expressions (regex)\r\n","\r\n","# natural language tool kits\r\n","from nltk.corpus import stopwords\r\n","import nltk\r\n","\r\n","# word2vec library\r\n","from gensim.models import word2vec\r\n","import itertools\r\n","\r\n","# Packages required for data preparation\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# library untuk Random forest\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"],"execution_count":153,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GpnvEbjSLfb"},"source":["# # path dataset\r\n","# data_path = r'/content/drive/MyDrive/Text Dataset/hate_speech.csv'\r\n","# dataset = pd.read_csv(data_path, header=0, sep = ',')\r\n","\r\n","# # dataset = dataset.reindex(np.random.permutation(dataset.index))  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":984},"id":"rDV7cUJwk1sO","executionInfo":{"status":"ok","timestamp":1608700808944,"user_tz":-420,"elapsed":1205,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"1d700a1b-2a78-4160-b403-e5bb816f5f03"},"source":["# path dataset\r\n","data_path = r'/content/drive/MyDrive/Text Dataset/sosmed-disaster.csv'\r\n","dataset = pd.read_csv(data_path, header=0, encoding='latin-1')\r\n","dataset.head(10)\r\n","# dataset = dataset.reindex(np.random.permutation(dataset.index))  "],"execution_count":182,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>_unit_id</th>\n","      <th>_golden</th>\n","      <th>_unit_state</th>\n","      <th>_trusted_judgments</th>\n","      <th>_last_judgment_at</th>\n","      <th>choose_one</th>\n","      <th>choose_one:confidence</th>\n","      <th>choose_one_gold</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>tweetid</th>\n","      <th>userid</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>778243823</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>156</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just happened a terrible car crash</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>778243824</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>152</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>13.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>778243825</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>137</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","      <td>14.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>778243826</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>136</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>0.9603</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","      <td>15.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>778243827</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>138</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>16.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>778243828</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>140</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>17.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>778243831</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>142</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>18.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>778243832</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>151</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>19.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>778243833</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>143</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>1.0000</td>\n","      <td>Relevant</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n","      <td>20.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>778243834</td>\n","      <td>True</td>\n","      <td>golden</td>\n","      <td>136</td>\n","      <td>NaN</td>\n","      <td>Relevant</td>\n","      <td>0.9606</td>\n","      <td>Relevant\\nCan't Decide</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","      <td>21.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    _unit_id  _golden  ... tweetid  userid\n","0  778243823     True  ...     1.0     NaN\n","1  778243824     True  ...    13.0     NaN\n","2  778243825     True  ...    14.0     NaN\n","3  778243826     True  ...    15.0     NaN\n","4  778243827     True  ...    16.0     NaN\n","5  778243828     True  ...    17.0     NaN\n","6  778243831     True  ...    18.0     NaN\n","7  778243832     True  ...    19.0     NaN\n","8  778243833     True  ...    20.0     NaN\n","9  778243834     True  ...    21.0     NaN\n","\n","[10 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":182}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"LPf_l78rSNVS","executionInfo":{"status":"ok","timestamp":1608700557227,"user_tz":-420,"elapsed":1506,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"9488a1eb-a71f-4c03-f483-588dbc29cd8b"},"source":["dataset = dataset[['text', 'choose_one']]\r\n","# # dataset.text = dataset.text.apply(remove_stopwords).apply(remove_mentions)\r\n","\r\n","dataset.head(10)"],"execution_count":172,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>choose_one</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Just happened a terrible car crash</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","      <td>Relevant</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text choose_one\n","0                 Just happened a terrible car crash   Relevant\n","1  Our Deeds are the Reason of this #earthquake M...   Relevant\n","2  Heard about #earthquake is different cities, s...   Relevant\n","3  there is a forest fire at spot pond, geese are...   Relevant\n","4             Forest fire near La Ronge Sask. Canada   Relevant\n","5  All residents asked to 'shelter in place' are ...   Relevant\n","6  13,000 people receive #wildfires evacuation or...   Relevant\n","7  Just got sent this photo from Ruby #Alaska as ...   Relevant\n","8  #RockyFire Update => California Hwy. 20 closed...   Relevant\n","9           Apocalypse lighting. #Spokane #wildfires   Relevant"]},"metadata":{"tags":[]},"execution_count":172}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":407},"id":"Z0VDGywv2cqh","executionInfo":{"status":"ok","timestamp":1608697826224,"user_tz":-420,"elapsed":1180,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"4f508a91-fc2a-47ea-ead5-37f258a63e26"},"source":["dataset.dropna(how='any')"],"execution_count":156,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>choose_one</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Just happened a terrible car crash</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10871</th>\n","      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>10872</th>\n","      <td>Police investigating after an e-bike collided ...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>10873</th>\n","      <td>The Latest: More Homes Razed by Northern Calif...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>10874</th>\n","      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n","      <td>Relevant</td>\n","    </tr>\n","    <tr>\n","      <th>10875</th>\n","      <td>#CityofCalgary has activated its Municipal Eme...</td>\n","      <td>Relevant</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10876 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text choose_one\n","0                     Just happened a terrible car crash   Relevant\n","1      Our Deeds are the Reason of this #earthquake M...   Relevant\n","2      Heard about #earthquake is different cities, s...   Relevant\n","3      there is a forest fire at spot pond, geese are...   Relevant\n","4                 Forest fire near La Ronge Sask. Canada   Relevant\n","...                                                  ...        ...\n","10871  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...   Relevant\n","10872  Police investigating after an e-bike collided ...   Relevant\n","10873  The Latest: More Homes Razed by Northern Calif...   Relevant\n","10874  MEG issues Hazardous Weather Outlook (HWO) htt...   Relevant\n","10875  #CityofCalgary has activated its Municipal Eme...   Relevant\n","\n","[10876 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":156}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BPq63MvOvh5E","executionInfo":{"status":"ok","timestamp":1608700820856,"user_tz":-420,"elapsed":1235,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"35d752dc-eb7d-4ecc-e89f-3dd062ee93a4"},"source":["dataset.isnull().any()"],"execution_count":183,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_unit_id                 False\n","_golden                  False\n","_unit_state              False\n","_trusted_judgments       False\n","_last_judgment_at         True\n","choose_one               False\n","choose_one:confidence    False\n","choose_one_gold           True\n","keyword                   True\n","location                  True\n","text                     False\n","tweetid                  False\n","userid                    True\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":183}]},{"cell_type":"code","metadata":{"id":"5kOegHJCaIJ_","executionInfo":{"status":"ok","timestamp":1608700846995,"user_tz":-420,"elapsed":1292,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# def remove_pattern(input_txt, pattern):\r\n","#     r = re.findall(pattern, input_txt)\r\n","#     for i in r:\r\n","#         input_txt = re.sub(i, '', input_txt)\r\n","        \r\n","#     return input_txt\r\n","\r\n","# # remove twitter handles (@user)\r\n","# dataset['tidy_tweet'] = np.vectorize(remove_pattern)(dataset['text'], \"@[\\w]*\")\r\n","\r\n","# remove special characters, numbers, punctuations\r\n","dataset['tidy_tweet'] = dataset['text'].str.replace(\"[^a-zA-Z#]\", \" \")\r\n","\r\n","# remove short word\r\n","dataset['tidy_tweet'] = dataset['tidy_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"],"execution_count":184,"outputs":[]},{"cell_type":"code","metadata":{"id":"7crWlW8LajPR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608696428341,"user_tz":-420,"elapsed":1114,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"c97c673f-e9db-4286-e956-95c5aa537690"},"source":["dataset.isnull().any()"],"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["text          False\n","choose_one    False\n","tidy_tweet    False\n","dtype: bool"]},"metadata":{"tags":[]},"execution_count":127}]},{"cell_type":"code","metadata":{"id":"LH9g4qqaSfb0","executionInfo":{"status":"ok","timestamp":1608700851833,"user_tz":-420,"elapsed":1178,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(dataset['tidy_tweet'], dataset['choose_one'], test_size = 0.2, random_state = 42)"],"execution_count":185,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0pONJ8ZS-MD","executionInfo":{"status":"ok","timestamp":1608696435744,"user_tz":-420,"elapsed":1168,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# proprocessing data teks\r\n","def review_wordlist(review, remove_stopwords=False):\r\n","    \r\n","    # # hapus simbol\r\n","    # review_text = re.sub(\"[^a-zA-Z]\",\" \",review)\r\n","    \r\n","    # # hapus @\r\n","    # review_text = re.sub(\"([^\\s\\w]|_@!?)+\",\" \", review_text)\r\n","\r\n","    # konversi ke huruf kecil dan dipisah perkata\r\n","    words = review.lower().split()\r\n","\r\n","    # menghapus stopwords\r\n","    if remove_stopwords:\r\n","        stops = set(stopwords.words(\"english\"))     \r\n","        words = [w for w in words if not w in stops]\r\n","    \r\n","    return(words)"],"execution_count":129,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UOCrGROTARL","executionInfo":{"status":"ok","timestamp":1608695502243,"user_tz":-420,"elapsed":1132,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"f6f902fe-8cd5-41cc-b66f-e06313887636"},"source":["# download file punctuation and stpwords\r\n","nltk.download('punkt')\r\n","nltk.download('stopwords')"],"execution_count":93,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":93}]},{"cell_type":"code","metadata":{"id":"kitMq0FPTB4y","executionInfo":{"status":"ok","timestamp":1608695505118,"user_tz":-420,"elapsed":1334,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# word2vec expects a list of lists.\r\n","# Using punkt tokenizer for better splitting of a paragraph into sentences.\r\n","\r\n","import nltk.data\r\n","#nltk.download('popular')\r\n","\r\n","tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"],"execution_count":94,"outputs":[]},{"cell_type":"code","metadata":{"id":"NL9QOUEmTDw6","executionInfo":{"status":"ok","timestamp":1608695509105,"user_tz":-420,"elapsed":1479,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Memisah review per kalimat\r\n","def review_sentences(review, tokenizer, remove_stopwords=False):\r\n","    \r\n","    # melakukan tokenize dengan nltk tokenizer\r\n","    raw_sentences = tokenizer.tokenize(review.strip())\r\n","    sentences = []\r\n","\r\n","    # mengisi array sentences dengan masing - masing review\r\n","    for raw_sentence in raw_sentences:\r\n","        if len(raw_sentence)>0:\r\n","            sentences.append(review_wordlist(raw_sentence, remove_stopwords))\r\n","\r\n","    # list dari list\r\n","    return sentences"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veX4_MtxTGE7","executionInfo":{"status":"ok","timestamp":1608700735288,"user_tz":-420,"elapsed":1195,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"b74f8e18-c286-49c3-e21c-5c58413e42f3"},"source":["sentences = []\r\n","print(\"Parsing sentences from training set\")\r\n","for review in X_train:\r\n","    sentences += review_sentences(review, tokenizer)"],"execution_count":177,"outputs":[{"output_type":"stream","text":["Parsing sentences from training set\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGDhEjxRTGoq","executionInfo":{"status":"ok","timestamp":1608700738239,"user_tz":-420,"elapsed":1160,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"b0f2dda2-5756-40ce-9e9e-7440a89f3bdb"},"source":["print(\"List dari lists. Cek tipe data : \", type(sentences), \" of \", type(sentences[0]))\r\n","# print(sentences)\r\n","print(sentences[0:10])\r\n","print(len(sentences))"],"execution_count":178,"outputs":[{"output_type":"stream","text":["List dari lists. Cek tipe data :  <class 'list'>  of  <class 'list'>\n","[['dont', 'even', 'remember', 'slsp', 'happening', 'just', 'remember', 'being', 'like', 'then', 'lights', 'turned', 'everyone', 'screamed', 'encore'], ['hazelannmac', 'feel', 'guilty', 'about', 'wishing', 'hatman', 'mudslide', 'delicious'], ['soultech', 'collide', 'club', 'http', 'xixbspot'], ['police', 'officer', 'wounded', 'suspect', 'dead', 'after', 'exchanging', 'shots', 'http', 'iphazv'], ['cramer', 'iger', 'words', 'that', 'wrecked', 'disney', 'stock', 'http', 'dgpbaivl'], ['safyuan', 'just', 'minor', 'citation', 'possesion', 'decriminalized', 'substance', 'facing', 'time'], ['thesmallclark', 'kill', 'instead', 'survived', 'shot', 'exactly', 'know', 'fled', 'scene', 'pulled', 'trigger', 'with'], ['could', 'demolish', 'this', 'right', 'https', 'jccrj'], ['national', 'park', 'services', 'tonto', 'national', 'forest', 'stop', 'annihilation', 'salt', 'river', 'wild', 'horse', 'https', 'fekgyby', 'change'], ['ashniggas', 'tink']]\n","8696\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7QzkWCw7Tua3","executionInfo":{"status":"ok","timestamp":1608695520875,"user_tz":-420,"elapsed":1309,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["best_score = []\r\n","best_parameter = []"],"execution_count":98,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0V-isSsFQCrw","executionInfo":{"status":"ok","timestamp":1608700866585,"user_tz":-420,"elapsed":4919,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"be7daf2e-393a-4702-8a12-371a118e2c8f"},"source":["# =================================================================================\r\n","# word2vec mulai disini\r\n","# =================================================================================\r\n","\r\n","# word2vec model\r\n","model = word2vec.Word2Vec(workers = 4, \r\n","                      size = 200, \r\n","                      min_count = 10, \r\n","                      window = 10)\r\n","model.build_vocab(sentences)\r\n","\r\n","# training model word2vec (CBOW, karena parameter 'sg' menggunakan nilai default)\r\n","print('\\n==============================================================')\r\n","print(\"Training model Word2Vec ...\")\r\n","print('==============================================================')\r\n","model.train(sentences = sentences, total_examples = len(sentences), epochs = 5)\r\n","\r\n","# Function to average all word vectors in a paragraph\r\n","def featureVecMethod(words, model, num_features):\r\n","    # Pre-initialising empty numpy array for speed\r\n","    featureVec = np.zeros(200,dtype=\"float32\")\r\n","    nwords = 0\r\n","    \r\n","    #Converting Index2Word which is a list to a set for better speed in the execution.\r\n","    index2word_set = set(model.wv.index2word)\r\n","    \r\n","    for word in  words:\r\n","        if word in index2word_set:\r\n","            nwords = nwords + 1\r\n","            featureVec = np.add(featureVec,model[word])\r\n","    \r\n","    # Dividing the result by number of words to get average\r\n","    featureVec = np.divide(featureVec, nwords)\r\n","    return featureVec\r\n","\r\n","# Function for calculating the average feature vector\r\n","def getAvgFeatureVecs(reviews, model, num_features):\r\n","    counter = 0\r\n","    reviewFeatureVecs = np.zeros((len(reviews),200),dtype=\"float32\")\r\n","    for review in reviews:\r\n","        # Printing a status message every 1000th review\r\n","        if counter%1000 == 0:\r\n","            print(\"Review %d of %d\"%(counter,len(reviews)))\r\n","            \r\n","        reviewFeatureVecs[counter] = featureVecMethod(review, model, 200)\r\n","        counter = counter+1\r\n","        \r\n","    return reviewFeatureVecs\r\n","\r\n","# Calculating average feature vector (mendapatkan vektor training set)\r\n","clean_train_reviews = []\r\n","for review in X_train:\r\n","    clean_train_reviews.append(review_wordlist(review, remove_stopwords=True))\r\n","    \r\n","trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, 200)\r\n","\r\n","# Calculating average feature vactors (mendapatkan vektor test set)     \r\n","clean_test_reviews = []\r\n","for review in X_test:\r\n","    clean_test_reviews.append(review_wordlist(review,remove_stopwords=True))\r\n","    \r\n","testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, 200)\r\n","\r\n","# tujuan masing-masing model word2vec, untuk mendapatkan 'trainDataVecs' dan 'testDataVecs' \r\n","# untuk diolah lebih lanjut di classifier\r\n","\r\n","# =================================================================================\r\n","# word2vec berakhir disini\r\n","# ================================================================================="],"execution_count":186,"outputs":[{"output_type":"stream","text":["\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 8700\n","Review 1000 of 8700\n","Review 2000 of 8700\n","Review 3000 of 8700"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Review 4000 of 8700\n","Review 5000 of 8700\n","Review 6000 of 8700\n","Review 7000 of 8700\n","Review 8000 of 8700\n","Review 0 of 2176\n","Review 1000 of 2176\n","Review 2000 of 2176\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"ztUK-WLQUYO1","executionInfo":{"status":"ok","timestamp":1608696680408,"user_tz":-420,"elapsed":1184,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"b8b3d676-8110-4b7f-c514-2a5de5b07e44"},"source":["model.doesnt_match(['car','pregnant','president','wild','nigguh'])"],"execution_count":139,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n","  \"\"\"Entry point for launching an IPython kernel.\n","/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'pregnant'"]},"metadata":{"tags":[]},"execution_count":139}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBEvMjozv8xu","executionInfo":{"status":"ok","timestamp":1608700772976,"user_tz":-420,"elapsed":1217,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"efda1ecd-f3ff-4fea-f0e9-bb60370427a0"},"source":["print(trainDataVecs.shape)\r\n","print(type(trainDataVecs[10][10]))\r\n","print(trainDataVecs[10])"],"execution_count":180,"outputs":[{"output_type":"stream","text":["(8700, 200)\n","<class 'numpy.float32'>\n","[-0.10271084 -0.03170505 -0.00098252 -0.18023546 -0.0228553   0.04365844\n","  0.05564448  0.04348141  0.01742684  0.03555949  0.06648624  0.16923879\n","  0.22512035 -0.01368562  0.10836975  0.01556964 -0.0257571   0.30390897\n","  0.13858673 -0.10075767  0.01463384 -0.0031422   0.05139892  0.00566258\n"," -0.08529083 -0.1414064   0.06621731 -0.14449589  0.2560714  -0.00662073\n"," -0.1119406  -0.17266543 -0.0371987  -0.10893557 -0.20561504 -0.13479587\n"," -0.00904985  0.17705944  0.03107837  0.2551353   0.04833467  0.13289365\n","  0.38831037  0.00733981 -0.09739133 -0.22222874  0.11374351 -0.09841061\n"," -0.14845452  0.08782728 -0.02101293  0.25709835 -0.0963615   0.02582991\n"," -0.10871396 -0.08586558  0.13421634 -0.18128519  0.07976219  0.09458257\n","  0.06633149 -0.16116491 -0.11419448  0.04752856  0.1435065  -0.12124445\n"," -0.06443848 -0.11143015  0.10988839 -0.00739202 -0.14813554  0.03208847\n"," -0.09342368  0.18080726  0.01476715 -0.24182959  0.14024012  0.02547339\n","  0.0873663   0.14612508 -0.10804249  0.14883506  0.04734719  0.01433797\n"," -0.03586962  0.07209013  0.09392919  0.03290214 -0.33302093 -0.05196773\n","  0.06771331 -0.17784047  0.01749603 -0.08780962 -0.28100115  0.07074139\n"," -0.14704672  0.00709195  0.20976758 -0.23475389 -0.14344916  0.12025176\n","  0.04688444  0.04146301 -0.14068314 -0.1658025   0.13216497 -0.11638925\n","  0.04172456  0.12941223  0.33711898 -0.05247074  0.00708244 -0.02002139\n"," -0.18932232 -0.17856605 -0.02208641 -0.1356452  -0.14914066 -0.41798678\n","  0.03459917 -0.09784941 -0.04712974 -0.17002852  0.02124504  0.04424805\n","  0.3738203  -0.07223685 -0.27047268 -0.05844356  0.04931807 -0.09708168\n"," -0.3147227  -0.27260518  0.2992099   0.08052553 -0.00310805  0.06563251\n"," -0.18062863  0.11564    -0.23039456 -0.04086081  0.05174605 -0.08681395\n","  0.1996527  -0.18902211 -0.11367999  0.01071547  0.389978    0.02682228\n","  0.28737098  0.09699806  0.04836509  0.19636902  0.00909538  0.03255347\n","  0.06440515  0.08928188  0.01070802  0.1186625  -0.01986541  0.03245444\n"," -0.03569766  0.04217024 -0.05734213  0.15476586 -0.08371373  0.00796945\n","  0.01494688  0.20761888 -0.30716872  0.2761516  -0.04396459  0.00935073\n","  0.09568037  0.14057942  0.13286084 -0.07043868 -0.03428666  0.09875363\n","  0.23185381 -0.14056367  0.02570568 -0.12013479 -0.13907738  0.03985895\n"," -0.13892794  0.00822397 -0.20116095  0.05410143 -0.11213823  0.12033117\n"," -0.00675584  0.06488764 -0.00335889 -0.02287466  0.18066683  0.01387147\n"," -0.07830053 -0.10191844]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YqhRUO34Rtm8","executionInfo":{"status":"ok","timestamp":1608696116926,"user_tz":-420,"elapsed":1177,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"74a07036-8463-41e1-9460-35c2cd32824b"},"source":["# np.isfinite(trainDataVecs)\r\n","# np.isnan(trainDataVecs)\r\n","print('\\n')\r\n","# np.where(np.isnan(trainDataVecs))\r\n","np.nan_to_num(trainDataVecs)"],"execution_count":120,"outputs":[{"output_type":"stream","text":["\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[-0.11027239, -0.0527853 ,  0.01780591, ...,  0.03072819,\n","        -0.09230059, -0.04021281],\n","       [-0.11575003, -0.05665668,  0.02204461, ...,  0.03352845,\n","        -0.09540892, -0.04044687],\n","       [-0.13312593, -0.06721942,  0.01607215, ...,  0.04303947,\n","        -0.11139769, -0.04966934],\n","       ...,\n","       [-0.13963467, -0.06781787,  0.02091169, ...,  0.04092883,\n","        -0.11604854, -0.05155595],\n","       [-0.11602937, -0.05895108,  0.01659537, ...,  0.03518617,\n","        -0.09946667, -0.04283651],\n","       [-0.09914498, -0.04959012,  0.0138425 , ...,  0.03421538,\n","        -0.08551119, -0.03520462]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":120}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pmSHGQTBTaWa","executionInfo":{"status":"ok","timestamp":1608695616807,"user_tz":-420,"elapsed":1146,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"25a0eed8-56db-4d19-c686-45e6b0520aaa"},"source":["np.nan_to_num(testDataVecs)"],"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.1110994 , -0.08648997,  0.01211994, ..., -0.00258085,\n","        -0.11481857, -0.04226538],\n","       [-0.17175099, -0.13346897,  0.01741779, ...,  0.00241178,\n","        -0.18210906, -0.06156302],\n","       [-0.11974993, -0.09258076,  0.01487163, ..., -0.00138354,\n","        -0.12524632, -0.04453228],\n","       ...,\n","       [-0.11395289, -0.08568748,  0.01341498, ..., -0.00245851,\n","        -0.11738835, -0.04216096],\n","       [-0.16710521, -0.12803331,  0.01367831, ..., -0.00448012,\n","        -0.18194926, -0.06190185],\n","       [-0.11338797, -0.09068947,  0.0116854 , ..., -0.00114231,\n","        -0.12670566, -0.04285615]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":103}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxadiWa6xhLZ","executionInfo":{"status":"ok","timestamp":1608700887009,"user_tz":-420,"elapsed":1137,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"727fc2cd-44d1-45b0-8b07-b36bfc1d7154"},"source":["np.any(np.isinf(trainDataVecs))"],"execution_count":187,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":187}]},{"cell_type":"code","metadata":{"id":"Fxi7henlzu4G","executionInfo":{"status":"ok","timestamp":1608697918536,"user_tz":-420,"elapsed":1216,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["from sklearn.preprocessing import StandardScaler\r\n","\r\n","# normalisasi\r\n","# atr_train = StandardScaler().fit_transform(atr_train)\r\n","# sc = StandardScaler()\r\n","\r\n","trainDataVecs = StandardScaler().fit_transform(trainDataVecs)\r\n","testDataVecs = sc.fit(testDataVecs)"],"execution_count":163,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":839},"id":"yhXJtVwZRgsz","executionInfo":{"status":"error","timestamp":1608700891006,"user_tz":-420,"elapsed":1206,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"254a451e-bf72-4ff6-e10e-fd08ab99f194"},"source":["print('\\n==============================================================')\r\n","print('Sentiment Analysis Process ...')\r\n","print('==============================================================')\r\n","# Memanggil classifier\r\n","score, report = classification_model(trainDataVecs, testDataVecs, y_train, y_test)\r\n","\r\n","print(f'Score : {score}')"],"execution_count":188,"outputs":[{"output_type":"stream","text":["\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-188-2981652bafb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=============================================================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Memanggil classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataVecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDataVecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Score : {score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-a864b203000a>\u001b[0m in \u001b[0;36mclassification_model\u001b[0;34m(train_feature_vec, test_feature_vec, train_sentiment, test_sentiment)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Fit random forest classifier ke data training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Prediksi nilai sentiment untuk test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."]}]},{"cell_type":"markdown","metadata":{"id":"VubRhsRKRiAo"},"source":["**SEACRH**"]},{"cell_type":"code","metadata":{"id":"sJaaVyLnTv7x"},"source":["# parameter yang akan dioptimasi\r\n","parm_dict = {\r\n","    'workers' : (4,),\r\n","    'size' : (300, 350, 400, 450, 500, 550, 600),\r\n","    'min_count' : (40,),\r\n","    'window' : (10,)\r\n","}\r\n","\r\n","# melakukan x, dengan metode y, untuk z \r\n","# optimization of feature dimension on word embedding based on vector size using grid search for sentimen analysis\r\n","\r\n","def cust_param_search(parm_dict):\r\n","\r\n","    score_best, parm_best = 0,()\r\n","    workers, size, min_count, window = [tup for k,tup in parm_dict.items()] # Individual parm tuples\r\n","    parm_combo = list(itertools.product(workers, size, min_count, window)) # Create all combinations\r\n","    \r\n","    print('\\n==============================================================')\r\n","    print('PARAMETER')\r\n","    print('==============================================================')\r\n","    print(f'Total kombinasi parameter   : {len(parm_combo)}')\r\n","    print(f'Semua kombinasi parameter   : {parm_combo}')\r\n","\r\n","    # Grid search\r\n","    i = 1\r\n","    for parms in parm_combo:\r\n","\r\n","        print('\\n==============================================================')\r\n","        print(f'{i}.\\t Parameter : {parms}')\r\n","        print('==============================================================')\r\n","        \r\n","        w, s, m, wi = parms\r\n","        \r\n","        # =================================================================================\r\n","        # word2vec mulai disini\r\n","        # =================================================================================\r\n","        \r\n","        # word2vec model\r\n","        model = word2vec.Word2Vec(workers = w, \r\n","                              size = s, \r\n","                              min_count = m, \r\n","                              window = wi)\r\n","        model.build_vocab(sentences)\r\n","\r\n","        # training model word2vec (CBOW, karena parameter 'sg' menggunakan nilai default)\r\n","        print('\\n==============================================================')\r\n","        print(\"Training model Word2Vec ...\")\r\n","        print('==============================================================')\r\n","        model.train(sentences = sentences, total_examples = len(sentences), epochs = 5)\r\n","\r\n","        # Function to average all word vectors in a paragraph\r\n","        def featureVecMethod(words, model, num_features):\r\n","            # Pre-initialising empty numpy array for speed\r\n","            featureVec = np.zeros(s,dtype=\"float32\")\r\n","            nwords = 0\r\n","            \r\n","            #Converting Index2Word which is a list to a set for better speed in the execution.\r\n","            index2word_set = set(model.wv.index2word)\r\n","            \r\n","            for word in  words:\r\n","                if word in index2word_set:\r\n","                    nwords = nwords + 1\r\n","                    featureVec = np.add(featureVec,model[word])\r\n","            \r\n","            # Dividing the result by number of words to get average\r\n","            featureVec = np.divide(featureVec, nwords)\r\n","            return featureVec\r\n","\r\n","        # Function for calculating the average feature vector\r\n","        def getAvgFeatureVecs(reviews, model, num_features):\r\n","            counter = 0\r\n","            reviewFeatureVecs = np.zeros((len(reviews),s),dtype=\"float32\")\r\n","            for review in reviews:\r\n","                # Printing a status message every 1000th review\r\n","                if counter%1000 == 0:\r\n","                    print(\"Review %d of %d\"%(counter,len(reviews)))\r\n","                    \r\n","                reviewFeatureVecs[counter] = featureVecMethod(review, model, s)\r\n","                counter = counter+1\r\n","                \r\n","            return reviewFeatureVecs\r\n","\r\n","        # Calculating average feature vector (mendapatkan vektor training set)\r\n","        clean_train_reviews = []\r\n","        for review in X_train:\r\n","            clean_train_reviews.append(review_wordlist(review, remove_stopwords=True))\r\n","            \r\n","        trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, s)\r\n","\r\n","        # Calculating average feature vactors (mendapatkan vektor test set)     \r\n","        clean_test_reviews = []\r\n","        for review in X_test:\r\n","            clean_test_reviews.append(review_wordlist(review,remove_stopwords=True))\r\n","            \r\n","        testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, s)\r\n","\r\n","        # tujuan masing-masing model word2vec, untuk mendapatkan 'trainDataVecs' dan 'testDataVecs' \r\n","        # untuk diolah lebih lanjut di classifier\r\n","        \r\n","        # =================================================================================\r\n","        # word2vec berakhir disini\r\n","        # =================================================================================\r\n","\r\n","        print('\\n==============================================================')\r\n","        print('Sentiment Analysis Process ...')\r\n","        print('==============================================================')\r\n","        # Memanggil classifier\r\n","        score, report = classification_model(trainDataVecs, testDataVecs, y_train, y_test)\r\n","\r\n","        # temporary print\r\n","        print('\\n==============================================================')\r\n","        print(f'Hasil Test Parameter ke - {i}')\r\n","        print(f'Parameter  => {parms}')\r\n","        print(f'Accuracy   => {score}')\r\n","        print(f'Classification Report => \\n {report}')\r\n","\r\n","        best_score.append(score)\r\n","        best_parameter.append(parms)\r\n","        \r\n","        if score > score_best:\r\n","            score_best = score\r\n","            parm_best = parms\r\n","        \r\n","        i = i + 1\r\n","    \r\n","    print('\\n==============================================================')\r\n","    print(f'Best Parameter  => {parm_best}')\r\n","    print(f'Accuracy   => {score_best}')\r\n","    print('==============================================================')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Yr7ivV-Twn_"},"source":["def classification_model(train_feature_vec, test_feature_vec, train_sentiment, test_sentiment):\r\n","\r\n","    # Model/classifier yang dipakai bebas\r\n","    # Fit random forest classifier ke data training\r\n","    forest = RandomForestClassifier(n_estimators = 100)    \r\n","    forest = forest.fit(train_feature_vec, train_sentiment) \r\n","\r\n","    # Prediksi nilai sentiment untuk test data \r\n","    predicted = forest.predict(test_feature_vec)\r\n","\r\n","    # akurasi\r\n","    accuracy = accuracy_score(test_sentiment, predicted)\r\n","    report = classification_report(test_sentiment, predicted, digits = 5)\r\n","    \r\n","    return accuracy, report"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Z-mIgJbXTyvN","executionInfo":{"status":"error","timestamp":1608687199703,"user_tz":-420,"elapsed":5845,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"576e3bec-3cb2-416f-d6b8-7d7adb899e35"},"source":["# test drive ma men (estimasi running : 21.30)\r\n","cust_param_search(parm_dict)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","==============================================================\n","PARAMETER\n","==============================================================\n","Total kombinasi parameter   : 7\n","Semua kombinasi parameter   : [(4, 300, 40, 10), (4, 350, 40, 10), (4, 400, 40, 10), (4, 450, 40, 10), (4, 500, 40, 10), (4, 550, 40, 10), (4, 600, 40, 10)]\n","\n","==============================================================\n","1.\t Parameter : (4, 300, 40, 10)\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 19826\n","Review 1000 of 19826\n","Review 2000 of 19826\n","Review 3000 of 19826\n","Review 4000 of 19826\n","Review 5000 of 19826\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n"],"name":"stderr"},{"output_type":"stream","text":["Review 6000 of 19826\n","Review 7000 of 19826\n","Review 8000 of 19826\n","Review 9000 of 19826\n","Review 10000 of 19826\n","Review 11000 of 19826\n","Review 12000 of 19826\n","Review 13000 of 19826\n","Review 14000 of 19826\n","Review 15000 of 19826\n","Review 16000 of 19826\n","Review 17000 of 19826\n","Review 18000 of 19826\n","Review 19000 of 19826\n","Review 0 of 4957\n","Review 1000 of 4957\n","Review 2000 of 4957\n","Review 3000 of 4957\n","Review 4000 of 4957\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-5bb2ee1fd4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test drive ma men (estimasi running : 21.30)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcust_param_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparm_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-cb1a5dff8939>\u001b[0m in \u001b[0;36mcust_param_search\u001b[0;34m(parm_dict)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'=============================================================='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Memanggil classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainDataVecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestDataVecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# temporary print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-a864b203000a>\u001b[0m in \u001b[0;36mclassification_model\u001b[0;34m(train_feature_vec, test_feature_vec, train_sentiment, test_sentiment)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Fit random forest classifier ke data training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feature_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Prediksi nilai sentiment untuk test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."]}]},{"cell_type":"code","metadata":{"id":"445wL9qcT64L"},"source":["print(best_score)\r\n","print(best_parameter)"],"execution_count":null,"outputs":[]}]}