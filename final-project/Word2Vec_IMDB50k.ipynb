{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Word2Vec_IMDB50k.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNSPUevfSQxE/kDYJmyiXF3"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"mt7MBfCXPxDG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609730684224,"user_tz":-420,"elapsed":1046,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"ebc890a9-8fa1-4135-e3bc-6c6ea1e2c557"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GH-tl6_aUxQP","executionInfo":{"status":"ok","timestamp":1609730686680,"user_tz":-420,"elapsed":3496,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Importing library\r\n","import numpy as np\r\n","import pandas as pd\r\n","\r\n","# BeautifulSoup = hapus tag html\r\n","from bs4 import BeautifulSoup \r\n","import re # regular expressions (regex)\r\n","\r\n","# natural language tool kits\r\n","from nltk.corpus import stopwords\r\n","import nltk"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKw3fIHNkl8K","executionInfo":{"status":"ok","timestamp":1609730688608,"user_tz":-420,"elapsed":5420,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# path dataset\r\n","data_path = r'/content/drive/MyDrive/Text Dataset/IMDB Dataset.csv'\r\n","\r\n","# Read data from files\r\n","dataset = pd.read_csv(data_path, header=0, sep = ',')\r\n","\r\n","# splitting data\r\n","train = dataset[0:39999]\r\n","test = dataset[40000:49999]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"TXCTz5ikQ9y3","executionInfo":{"status":"ok","timestamp":1609730688611,"user_tz":-420,"elapsed":5420,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# proprocessing data teks\r\n","def review_wordlist(review, remove_stopwords=False):\r\n","    \r\n","    # hapus tag html\r\n","    review_text = BeautifulSoup(review).get_text()\r\n","    \r\n","    # hapus simbol\r\n","    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\r\n","    \r\n","    # konversi ke huruf kecil dan dipisah perkata\r\n","    words = review_text.lower().split()\r\n","\r\n","    # menghapus stopwords\r\n","    if remove_stopwords:\r\n","        stops = set(stopwords.words(\"english\"))     \r\n","        words = [w for w in words if not w in stops]\r\n","    \r\n","    return(words)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m3cR7-_CTBXd","executionInfo":{"status":"ok","timestamp":1609730688972,"user_tz":-420,"elapsed":5747,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"c1557af5-06e2-41cc-f429-03062d2f197d"},"source":["# download file punctuation and stpwords\r\n","nltk.download('punkt')\r\n","nltk.download('stopwords')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"MB1l-Mb3RM5w","executionInfo":{"status":"ok","timestamp":1609730688974,"user_tz":-420,"elapsed":5746,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# word2vec expects a list of lists.\r\n","# Using punkt tokenizer for better splitting of a paragraph into sentences.\r\n","\r\n","import nltk.data\r\n","#nltk.download('popular')\r\n","\r\n","tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccr8a9BhRQ42","executionInfo":{"status":"ok","timestamp":1609730688976,"user_tz":-420,"elapsed":5744,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# This function splits a review into sentences\r\n","def review_sentences(review, tokenizer, remove_stopwords=False):\r\n","    # melakukan tokenize dengan nltk tokenizer\r\n","    raw_sentences = tokenizer.tokenize(review.strip())\r\n","    sentences = []\r\n","\r\n","    # mengisi array sentences dengan masing - masing review\r\n","    for raw_sentence in raw_sentences:\r\n","        if len(raw_sentence)>0:\r\n","            sentences.append(review_wordlist(raw_sentence,\\\r\n","                                            remove_stopwords))\r\n","\r\n","    # list dari list\r\n","    return sentences"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecEk1fq-TUR3","executionInfo":{"status":"ok","timestamp":1609730799705,"user_tz":-420,"elapsed":116429,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"da0da3f6-26a6-424b-a7ea-44bd9b60d85c"},"source":["sentences = []\r\n","print(\"Parsing sentences from training set\")\r\n","for review in train[\"review\"]:\r\n","    sentences += review_sentences(review, tokenizer)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Parsing sentences from training set\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  ' Beautiful Soup.' % markup)\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:273: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n","  ' Beautiful Soup.' % markup)\n","/usr/local/lib/python3.6/dist-packages/bs4/__init__.py:336: UserWarning: \"http://www.happierabroad.com\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  ' that document to Beautiful Soup.' % decoded_markup\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"63-o44ppTslV","executionInfo":{"status":"ok","timestamp":1609730799723,"user_tz":-420,"elapsed":116442,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Importing the built-in logging module\r\n","import logging\r\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uLVbdqa6UVdB","executionInfo":{"status":"ok","timestamp":1609730799728,"user_tz":-420,"elapsed":116404,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"350f4d5b-fe91-4eb4-e1be-f81fbecdc27f"},"source":["print(\"List of lists. Let's confirm: \", type(sentences), \" of \", type(sentences[0]))\r\n","print(sentences[10])\r\n","print(len(sentences))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["List of lists. Let's confirm:  <class 'list'>  of  <class 'list'>\n","['a', 'wonderful', 'little', 'production']\n","428144\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4_LAa2qcebhV","executionInfo":{"status":"ok","timestamp":1609731524135,"user_tz":-420,"elapsed":1210,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# membuat model dan mengatur nilai parameter\r\n","num_features = 300  # Word vector dimensionality\r\n","min_word_count = 40 # Minimum word count\r\n","num_workers = 4     # Number of parallel threads\r\n","context = 10        # Context window size\r\n","downsampling = 0.001 # (0.001) Downsample setting for frequent words"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyHef0fiTxyU","executionInfo":{"status":"ok","timestamp":1609731404443,"user_tz":-420,"elapsed":14241,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"322d59c2-fbb7-483d-e1c7-9c053e39456d"},"source":["\r\n","\r\n","# Inisialisasi model\r\n","from gensim.models import word2vec\r\n","# model = word2vec.Word2Vec(workers = num_workers, \r\n","#                           size = num_features, \r\n","#                           min_count = min_word_count, \r\n","#                           window = context, \r\n","#                           sg = 1, # sg = 1 (skipgram), default/0 adalah cbow\r\n","#                           sample = downsampling)\r\n","model = word2vec.Word2Vec(size = 300)\r\n","model.build_vocab(sentences)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["2021-01-04 03:37:07,972 : INFO : collecting all words and their counts\n","2021-01-04 03:37:07,975 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n","2021-01-04 03:37:08,036 : INFO : PROGRESS: at sentence #10000, processed 224307 words, keeping 17319 word types\n","2021-01-04 03:37:08,092 : INFO : PROGRESS: at sentence #20000, processed 434605 words, keeping 24175 word types\n","2021-01-04 03:37:08,157 : INFO : PROGRESS: at sentence #30000, processed 655533 words, keeping 29419 word types\n","2021-01-04 03:37:08,220 : INFO : PROGRESS: at sentence #40000, processed 877306 words, keeping 33897 word types\n","2021-01-04 03:37:08,278 : INFO : PROGRESS: at sentence #50000, processed 1100000 words, keeping 37667 word types\n","2021-01-04 03:37:08,343 : INFO : PROGRESS: at sentence #60000, processed 1324580 words, keeping 40923 word types\n","2021-01-04 03:37:08,404 : INFO : PROGRESS: at sentence #70000, processed 1543432 words, keeping 43631 word types\n","2021-01-04 03:37:08,468 : INFO : PROGRESS: at sentence #80000, processed 1757050 words, keeping 46072 word types\n","2021-01-04 03:37:08,532 : INFO : PROGRESS: at sentence #90000, processed 1976526 words, keeping 48547 word types\n","2021-01-04 03:37:08,597 : INFO : PROGRESS: at sentence #100000, processed 2199610 words, keeping 50850 word types\n","2021-01-04 03:37:08,663 : INFO : PROGRESS: at sentence #110000, processed 2412028 words, keeping 52887 word types\n","2021-01-04 03:37:08,729 : INFO : PROGRESS: at sentence #120000, processed 2631483 words, keeping 54897 word types\n","2021-01-04 03:37:08,794 : INFO : PROGRESS: at sentence #130000, processed 2852491 words, keeping 56806 word types\n","2021-01-04 03:37:08,866 : INFO : PROGRESS: at sentence #140000, processed 3074705 words, keeping 58479 word types\n","2021-01-04 03:37:08,933 : INFO : PROGRESS: at sentence #150000, processed 3290599 words, keeping 59976 word types\n","2021-01-04 03:37:08,998 : INFO : PROGRESS: at sentence #160000, processed 3503070 words, keeping 61583 word types\n","2021-01-04 03:37:09,075 : INFO : PROGRESS: at sentence #170000, processed 3718687 words, keeping 63166 word types\n","2021-01-04 03:37:09,157 : INFO : PROGRESS: at sentence #180000, processed 3941039 words, keeping 64688 word types\n","2021-01-04 03:37:09,226 : INFO : PROGRESS: at sentence #190000, processed 4159717 words, keeping 66133 word types\n","2021-01-04 03:37:09,294 : INFO : PROGRESS: at sentence #200000, processed 4377455 words, keeping 67536 word types\n","2021-01-04 03:37:09,366 : INFO : PROGRESS: at sentence #210000, processed 4593514 words, keeping 68843 word types\n","2021-01-04 03:37:09,436 : INFO : PROGRESS: at sentence #220000, processed 4813310 words, keeping 70117 word types\n","2021-01-04 03:37:09,503 : INFO : PROGRESS: at sentence #230000, processed 5034508 words, keeping 71484 word types\n","2021-01-04 03:37:09,569 : INFO : PROGRESS: at sentence #240000, processed 5255583 words, keeping 72687 word types\n","2021-01-04 03:37:09,631 : INFO : PROGRESS: at sentence #250000, processed 5476579 words, keeping 73951 word types\n","2021-01-04 03:37:09,693 : INFO : PROGRESS: at sentence #260000, processed 5694195 words, keeping 75064 word types\n","2021-01-04 03:37:09,757 : INFO : PROGRESS: at sentence #270000, processed 5913181 words, keeping 76181 word types\n","2021-01-04 03:37:09,822 : INFO : PROGRESS: at sentence #280000, processed 6134877 words, keeping 77335 word types\n","2021-01-04 03:37:09,890 : INFO : PROGRESS: at sentence #290000, processed 6349950 words, keeping 78484 word types\n","2021-01-04 03:37:09,959 : INFO : PROGRESS: at sentence #300000, processed 6569736 words, keeping 79593 word types\n","2021-01-04 03:37:10,025 : INFO : PROGRESS: at sentence #310000, processed 6786686 words, keeping 80756 word types\n","2021-01-04 03:37:10,099 : INFO : PROGRESS: at sentence #320000, processed 7007919 words, keeping 81790 word types\n","2021-01-04 03:37:10,176 : INFO : PROGRESS: at sentence #330000, processed 7225676 words, keeping 82863 word types\n","2021-01-04 03:37:10,253 : INFO : PROGRESS: at sentence #340000, processed 7442546 words, keeping 83964 word types\n","2021-01-04 03:37:10,332 : INFO : PROGRESS: at sentence #350000, processed 7662724 words, keeping 84962 word types\n","2021-01-04 03:37:10,411 : INFO : PROGRESS: at sentence #360000, processed 7877591 words, keeping 85892 word types\n","2021-01-04 03:37:10,488 : INFO : PROGRESS: at sentence #370000, processed 8097606 words, keeping 86955 word types\n","2021-01-04 03:37:10,571 : INFO : PROGRESS: at sentence #380000, processed 8314768 words, keeping 87912 word types\n","2021-01-04 03:37:10,646 : INFO : PROGRESS: at sentence #390000, processed 8528660 words, keeping 88820 word types\n","2021-01-04 03:37:10,725 : INFO : PROGRESS: at sentence #400000, processed 8743911 words, keeping 89812 word types\n","2021-01-04 03:37:10,806 : INFO : PROGRESS: at sentence #410000, processed 8961785 words, keeping 90762 word types\n","2021-01-04 03:37:10,880 : INFO : PROGRESS: at sentence #420000, processed 9174372 words, keeping 91593 word types\n","2021-01-04 03:37:10,941 : INFO : collected 92280 word types from a corpus of 9353984 raw words and 428144 sentences\n","2021-01-04 03:37:10,942 : INFO : Loading a fresh vocabulary\n","2021-01-04 03:37:11,050 : INFO : effective_min_count=5 retains 35644 unique words (38% of original 92280, drops 56636)\n","2021-01-04 03:37:11,051 : INFO : effective_min_count=5 leaves 9261238 word corpus (99% of original 9353984, drops 92746)\n","2021-01-04 03:37:11,191 : INFO : deleting the raw counts dictionary of 92280 items\n","2021-01-04 03:37:11,197 : INFO : sample=0.001 downsamples 48 most-common words\n","2021-01-04 03:37:11,198 : INFO : downsampling leaves estimated 6920220 word corpus (74.7% of prior 9261238)\n","2021-01-04 03:37:11,371 : INFO : estimated required memory for 35644 words and 300 dimensions: 103367600 bytes\n","2021-01-04 03:37:11,372 : INFO : resetting layer weights\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dv2mtumZg9lQ","executionInfo":{"status":"ok","timestamp":1609731456364,"user_tz":-420,"elapsed":44128,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"ddf8c406-ad19-4233-e756-69153513c3c4"},"source":["print(\"Training model....\")\r\n","# model.train(sentences = sentences, total_examples = len(sentences), epochs = model.iter)\r\n","model.train(sentences = sentences, total_examples = len(sentences), epochs = 2)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["2021-01-04 03:37:30,017 : INFO : training model with 3 workers on 35644 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n"],"name":"stderr"},{"output_type":"stream","text":["Training model....\n"],"name":"stdout"},{"output_type":"stream","text":["2021-01-04 03:37:31,048 : INFO : EPOCH 1 - PROGRESS: at 4.39% examples, 299940 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:32,053 : INFO : EPOCH 1 - PROGRESS: at 8.83% examples, 304504 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:33,082 : INFO : EPOCH 1 - PROGRESS: at 13.33% examples, 305796 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:34,094 : INFO : EPOCH 1 - PROGRESS: at 17.80% examples, 305912 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:35,122 : INFO : EPOCH 1 - PROGRESS: at 22.38% examples, 306529 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:36,141 : INFO : EPOCH 1 - PROGRESS: at 26.99% examples, 307230 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:37,153 : INFO : EPOCH 1 - PROGRESS: at 31.64% examples, 309150 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:38,158 : INFO : EPOCH 1 - PROGRESS: at 36.37% examples, 310923 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:39,174 : INFO : EPOCH 1 - PROGRESS: at 41.03% examples, 311153 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:40,186 : INFO : EPOCH 1 - PROGRESS: at 45.82% examples, 312913 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:41,193 : INFO : EPOCH 1 - PROGRESS: at 50.72% examples, 315124 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:42,231 : INFO : EPOCH 1 - PROGRESS: at 55.59% examples, 316123 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:43,253 : INFO : EPOCH 1 - PROGRESS: at 60.35% examples, 316820 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:44,254 : INFO : EPOCH 1 - PROGRESS: at 64.90% examples, 316882 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:45,282 : INFO : EPOCH 1 - PROGRESS: at 69.62% examples, 316814 words/s, in_qsize 6, out_qsize 1\n","2021-01-04 03:37:46,315 : INFO : EPOCH 1 - PROGRESS: at 73.97% examples, 315324 words/s, in_qsize 3, out_qsize 2\n","2021-01-04 03:37:47,340 : INFO : EPOCH 1 - PROGRESS: at 78.49% examples, 314573 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:48,342 : INFO : EPOCH 1 - PROGRESS: at 82.74% examples, 313489 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:49,347 : INFO : EPOCH 1 - PROGRESS: at 87.16% examples, 312841 words/s, in_qsize 6, out_qsize 2\n","2021-01-04 03:37:50,388 : INFO : EPOCH 1 - PROGRESS: at 91.60% examples, 311709 words/s, in_qsize 6, out_qsize 0\n","2021-01-04 03:37:51,404 : INFO : EPOCH 1 - PROGRESS: at 95.78% examples, 310373 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:52,274 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-01-04 03:37:52,283 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-01-04 03:37:52,301 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-01-04 03:37:52,302 : INFO : EPOCH - 1 : training on 9353984 raw words (6921201 effective words) took 22.3s, 310869 effective words/s\n","2021-01-04 03:37:53,352 : INFO : EPOCH 2 - PROGRESS: at 4.82% examples, 320219 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:54,367 : INFO : EPOCH 2 - PROGRESS: at 9.47% examples, 320180 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:55,368 : INFO : EPOCH 2 - PROGRESS: at 14.25% examples, 326302 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:56,388 : INFO : EPOCH 2 - PROGRESS: at 19.12% examples, 326051 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:57,411 : INFO : EPOCH 2 - PROGRESS: at 23.97% examples, 327231 words/s, in_qsize 4, out_qsize 1\n","2021-01-04 03:37:58,421 : INFO : EPOCH 2 - PROGRESS: at 29.12% examples, 330940 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:37:59,473 : INFO : EPOCH 2 - PROGRESS: at 33.97% examples, 329791 words/s, in_qsize 5, out_qsize 1\n","2021-01-04 03:38:00,484 : INFO : EPOCH 2 - PROGRESS: at 38.90% examples, 329625 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:01,503 : INFO : EPOCH 2 - PROGRESS: at 43.54% examples, 328492 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:02,508 : INFO : EPOCH 2 - PROGRESS: at 48.51% examples, 329403 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:03,552 : INFO : EPOCH 2 - PROGRESS: at 53.16% examples, 327712 words/s, in_qsize 6, out_qsize 0\n","2021-01-04 03:38:04,573 : INFO : EPOCH 2 - PROGRESS: at 57.79% examples, 326889 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:05,593 : INFO : EPOCH 2 - PROGRESS: at 62.59% examples, 326790 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:06,594 : INFO : EPOCH 2 - PROGRESS: at 67.50% examples, 327658 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:07,596 : INFO : EPOCH 2 - PROGRESS: at 72.29% examples, 327942 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:08,609 : INFO : EPOCH 2 - PROGRESS: at 76.97% examples, 327481 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:09,635 : INFO : EPOCH 2 - PROGRESS: at 81.89% examples, 327715 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:10,638 : INFO : EPOCH 2 - PROGRESS: at 86.83% examples, 328303 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:11,662 : INFO : EPOCH 2 - PROGRESS: at 91.81% examples, 328474 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:12,673 : INFO : EPOCH 2 - PROGRESS: at 96.86% examples, 329239 words/s, in_qsize 5, out_qsize 0\n","2021-01-04 03:38:13,303 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-01-04 03:38:13,313 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-01-04 03:38:13,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-01-04 03:38:13,345 : INFO : EPOCH - 2 : training on 9353984 raw words (6919497 effective words) took 21.0s, 328972 effective words/s\n","2021-01-04 03:38:13,347 : INFO : training on a 18707968 raw words (13840698 effective words) took 43.3s, 319455 effective words/s\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(13840698, 18707968)"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"LMnNJW_unWhB","executionInfo":{"status":"ok","timestamp":1609730918083,"user_tz":-420,"elapsed":234679,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# menyimpan model untuk kebutuhan selanjutnya\r\n","# model_name = \"300features_40minwords_10context\"\r\n","# model.save(model_name)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"bgqBP7N-j-Sd","executionInfo":{"status":"ok","timestamp":1609730918084,"user_tz":-420,"elapsed":234653,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"acbf4569-eb5b-48d6-86b1-34ac2735b17d"},"source":["# test : mencetak kata yang tidak ada hubunganya \r\n","model.wv.doesnt_match(\"man woman dog child kitchen\".split())"],"execution_count":15,"outputs":[{"output_type":"stream","text":["2021-01-04 03:29:14,718 : INFO : precomputing L2-norms of word weight vectors\n","/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'kitchen'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"7gs_i0SnkXB2","executionInfo":{"status":"ok","timestamp":1609730918085,"user_tz":-420,"elapsed":234626,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"3994281f-de85-42f0-cff7-6db7ba303c98"},"source":["model.wv.doesnt_match(\"france england germany berlin\".split())"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'berlin'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygxV1rCLkYbi","executionInfo":{"status":"ok","timestamp":1609730918086,"user_tz":-420,"elapsed":234602,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"0da80799-5865-4b8b-cc90-17ccf7d56cb0"},"source":["# mencetak kata yang paling mirip di dalam model\r\n","model.wv.most_similar(\"man\")"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('woman', 0.7549165487289429),\n"," ('boy', 0.708862841129303),\n"," ('guy', 0.7053457498550415),\n"," ('mans', 0.6648308634757996),\n"," ('monk', 0.650288999080658),\n"," ('lady', 0.6396517753601074),\n"," ('thug', 0.6378631591796875),\n"," ('girl', 0.6358193159103394),\n"," ('servant', 0.6319907903671265),\n"," ('pervert', 0.6261723041534424)]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h0uBvYTokZxK","executionInfo":{"status":"ok","timestamp":1609730918087,"user_tz":-420,"elapsed":234578,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"bf0a049f-2dba-4437-9a6f-7800382ca2d6"},"source":["model.wv.most_similar(\"awful\")"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('terrible', 0.87895667552948),\n"," ('dreadful', 0.8556897044181824),\n"," ('horrible', 0.8545076251029968),\n"," ('atrocious', 0.8503308296203613),\n"," ('appalling', 0.8303557634353638),\n"," ('horrendous', 0.8302174806594849),\n"," ('abysmal', 0.7890251874923706),\n"," ('horrid', 0.7852514982223511),\n"," ('laughable', 0.7789475321769714),\n"," ('bad', 0.7666476368904114)]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ti5Pp5b7kiiC","executionInfo":{"status":"ok","timestamp":1609730918088,"user_tz":-420,"elapsed":234544,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"50444870-b1b1-4200-c2ab-68fe2365837b"},"source":["# jumlah kata dalam vocab dari dataset \r\n","model.wv.syn0.shape"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n","  \n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["(11183, 100)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"TySiMKgrpN9I","executionInfo":{"status":"ok","timestamp":1609730918089,"user_tz":-420,"elapsed":234541,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Function to average all word vectors in a paragraph\r\n","def featureVecMethod(words, model, num_features):\r\n","    # Pre-initialising empty numpy array for speed\r\n","    featureVec = np.zeros(num_features,dtype=\"float32\")\r\n","    nwords = 0\r\n","    \r\n","    #Converting Index2Word which is a list to a set for better speed in the execution.\r\n","    index2word_set = set(model.wv.index2word)\r\n","    \r\n","    for word in  words:\r\n","        if word in index2word_set:\r\n","            nwords = nwords + 1\r\n","            featureVec = np.add(featureVec,model[word])\r\n","    \r\n","    # Dividing the result by number of words to get average\r\n","    featureVec = np.divide(featureVec, nwords)\r\n","    return featureVec"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wj6lZpeipf1t","executionInfo":{"status":"ok","timestamp":1609730918089,"user_tz":-420,"elapsed":234538,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Function for calculating the average feature vector\r\n","def getAvgFeatureVecs(reviews, model, num_features):\r\n","    counter = 0\r\n","    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\r\n","    for review in reviews:\r\n","        # Printing a status message every 1000th review\r\n","        if counter%1000 == 0:\r\n","            print(\"Review %d of %d\"%(counter,len(reviews)))\r\n","            \r\n","        reviewFeatureVecs[counter] = featureVecMethod(review, model, num_features)\r\n","        counter = counter+1\r\n","        \r\n","    return reviewFeatureVecs"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ofTMAedupjjK","executionInfo":{"status":"ok","timestamp":1609731894531,"user_tz":-420,"elapsed":353428,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"e11330d3-0eb2-460d-a69a-ac7622c41c98"},"source":["# Calculating average feature vector for training set\r\n","clean_train_reviews = []\r\n","for review in train['review']:\r\n","    clean_train_reviews.append(review_wordlist(review, remove_stopwords=True))\r\n","    \r\n","trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, num_features)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Review 0 of 39999\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"stream","text":["Review 1000 of 39999\n","Review 2000 of 39999\n","Review 3000 of 39999\n","Review 4000 of 39999\n","Review 5000 of 39999\n","Review 6000 of 39999\n","Review 7000 of 39999\n","Review 8000 of 39999\n","Review 9000 of 39999\n","Review 10000 of 39999\n","Review 11000 of 39999\n","Review 12000 of 39999\n","Review 13000 of 39999\n","Review 14000 of 39999\n","Review 15000 of 39999\n","Review 16000 of 39999\n","Review 17000 of 39999\n","Review 18000 of 39999\n","Review 19000 of 39999\n","Review 20000 of 39999\n","Review 21000 of 39999\n","Review 22000 of 39999\n","Review 23000 of 39999\n","Review 24000 of 39999\n","Review 25000 of 39999\n","Review 26000 of 39999\n","Review 27000 of 39999\n","Review 28000 of 39999\n","Review 29000 of 39999\n","Review 30000 of 39999\n","Review 31000 of 39999\n","Review 32000 of 39999\n","Review 33000 of 39999\n","Review 34000 of 39999\n","Review 35000 of 39999\n","Review 36000 of 39999\n","Review 37000 of 39999\n","Review 38000 of 39999\n","Review 39000 of 39999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Dlui75Spmls","executionInfo":{"status":"ok","timestamp":1609731984004,"user_tz":-420,"elapsed":87927,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"c6a2a9fd-3c40-4d66-c5e0-4234245306a8"},"source":["# Calculating average feature vactors for test set     \r\n","clean_test_reviews = []\r\n","for review in test[\"review\"]:\r\n","    clean_test_reviews.append(review_wordlist(review,remove_stopwords=True))\r\n","    \r\n","testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, num_features)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Review 0 of 9999\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  del sys.path[0]\n"],"name":"stderr"},{"output_type":"stream","text":["Review 1000 of 9999\n","Review 2000 of 9999\n","Review 3000 of 9999\n","Review 4000 of 9999\n","Review 5000 of 9999\n","Review 6000 of 9999\n","Review 7000 of 9999\n","Review 8000 of 9999\n","Review 9000 of 9999\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHk9sxmoq7hA","executionInfo":{"status":"ok","timestamp":1609731028874,"user_tz":-420,"elapsed":345222,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"55984745-1a2e-4775-bb39-b672900d614a"},"source":["print(trainDataVecs.shape)\r\n","print(testDataVecs.shape)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["(39999, 100)\n","(9999, 100)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aY7lzddb6RV5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1609731028875,"user_tz":-420,"elapsed":345195,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"e9d14dd1-2308-4b2e-bca3-8bb3e6fd87d5"},"source":["print(trainDataVecs[10])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[ 0.00823498  0.03644501  0.03218948  0.22181776  0.02433273  0.25639123\n","  0.12238596  0.04065422  0.01177646 -0.01663784 -0.1770446   0.16924544\n","  0.12316813  0.0390509   0.07543782  0.15042903  0.34172463 -0.08437014\n","  0.06878469 -0.07333653 -0.12533984 -0.2788143   0.09931821  0.08015273\n","  0.07894555 -0.02600707  0.00558659  0.00903116 -0.00805558  0.13014889\n","  0.21544307 -0.05873488  0.00982271  0.12977971  0.0286414   0.02313107\n"," -0.14247485  0.31120658  0.04083855  0.03913445 -0.14548099 -0.15282984\n"," -0.22545317  0.14096549 -0.05313232  0.0425006  -0.06810469  0.0937503\n","  0.03497593 -0.0038024   0.1857445  -0.05436939 -0.06605195  0.0439129\n","  0.07789018 -0.13019702 -0.08460937 -0.05584453 -0.04149645 -0.12297469\n"," -0.08209901 -0.2558594  -0.26634115  0.2636817  -0.00911715 -0.00616273\n","  0.1237504   0.02108551  0.12432893 -0.35028625  0.13643944 -0.01332242\n","  0.09356418 -0.05550663 -0.11320368 -0.09755907 -0.15731546  0.06794147\n"," -0.08227494  0.18442886 -0.04363215 -0.02113006 -0.04118946 -0.12470841\n","  0.01004962  0.22667238  0.10794225 -0.03925952 -0.1886116  -0.00297677\n"," -0.14962295  0.09623498  0.16250397  0.1674428  -0.01583838 -0.17816351\n","  0.03870821  0.24361601 -0.11825096  0.0570614 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RehATMJErpfg","executionInfo":{"status":"ok","timestamp":1609732068984,"user_tz":-420,"elapsed":84954,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"fb11e92f-959a-4592-ed40-7a992464a562"},"source":["# Fitting a random forest classifier to the training data\r\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","\r\n","forest = RandomForestClassifier(n_estimators = 100)\r\n","    \r\n","print(\"Fitting random forest to training data....\")    \r\n","forest = forest.fit(trainDataVecs, train[\"sentiment\"])\r\n","\r\n","# Prediksi nilai sentiment untuk test data \r\n","predicted = forest.predict(testDataVecs)\r\n","\r\n","# akurasi\r\n","accuracy = accuracy_score(test[\"sentiment\"], predicted)\r\n","report = classification_report(test[\"sentiment\"], predicted, digits = 5)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Fitting random forest to training data....\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-IrK77ndG5M","executionInfo":{"status":"ok","timestamp":1609732068989,"user_tz":-420,"elapsed":44549,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"0dd6884a-1baa-49a4-f463-ecfebb9d1941"},"source":["print(report)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    negative    0.80953   0.78586   0.79752      4992\n","    positive    0.79255   0.81566   0.80394      5007\n","\n","    accuracy                        0.80078      9999\n","   macro avg    0.80104   0.80076   0.80073      9999\n","weighted avg    0.80103   0.80078   0.80073      9999\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z-57YxzJrxeg","executionInfo":{"status":"ok","timestamp":1609731076316,"user_tz":-420,"elapsed":392595,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Predicting the sentiment values for test data and saving the results in a csv file \r\n","# result = forest.predict(testDataVecs)\r\n","# output = pd.DataFrame(data={\"id\":test[\"id\"], \"sentiment\":result})\r\n","# output.to_csv( \"output.csv\", index=False, quoting=3 )"],"execution_count":27,"outputs":[]}]}