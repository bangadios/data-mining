{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word2vec_tweetsAirline_grid.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO2vJPwPOxEN9BXgAWI0t0C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcxwR-N0ij_M","executionInfo":{"status":"ok","timestamp":1608646926471,"user_tz":-420,"elapsed":1129,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"caac5486-1d3d-461e-e360-9f51ccf87ff6"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"akVvBVLIjOuS","executionInfo":{"status":"ok","timestamp":1608646928565,"user_tz":-420,"elapsed":1132,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Importing library\r\n","import numpy as np\r\n","import pandas as pd\r\n","\r\n","# BeautifulSoup = hapus tag html\r\n","from bs4 import BeautifulSoup \r\n","import re # regular expressions (regex)\r\n","\r\n","# natural language tool kits\r\n","from nltk.corpus import stopwords\r\n","import nltk\r\n","\r\n","# word2vec library\r\n","from gensim.models import word2vec\r\n","import itertools\r\n","\r\n","# Packages required for data preparation\r\n","from sklearn.model_selection import train_test_split\r\n","\r\n","# library untuk Random forest\r\n","from sklearn.ensemble import RandomForestClassifier\r\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"5GiMMHR9n04E","executionInfo":{"status":"ok","timestamp":1608646932675,"user_tz":-420,"elapsed":1393,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# path dataset\r\n","data_path = r'/content/drive/MyDrive/Text Dataset/Tweets.csv'\r\n","dataset = pd.read_csv(data_path, header=0, sep = ',')\r\n","\r\n","dataset = dataset.reindex(np.random.permutation(dataset.index))  "],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"id":"GylrPxgso2BN","executionInfo":{"status":"ok","timestamp":1608646955975,"user_tz":-420,"elapsed":1085,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"87b40e6d-8db8-4e59-bbbe-1cba07212ec8"},"source":["dataset = dataset[['text', 'airline_sentiment']]\r\n","# dataset.text = dataset.text.apply(remove_stopwords).apply(remove_mentions)\r\n","\r\n","dataset.head(10)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>airline_sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14424</th>\n","      <td>@AmericanAir redirect my flight without tellin...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4108</th>\n","      <td>@united Call customer service and of course th...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>11786</th>\n","      <td>@USAirways Haha - that will indeed be a great ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3801</th>\n","      <td>@united trade show! Come by both 130 for aweso...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>10384</th>\n","      <td>@USAirways Can't stress enough how awful the a...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1412</th>\n","      <td>@united  bags left behind because plane overwe...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>5417</th>\n","      <td>@SouthwestAir Suggestions: tell customers appr...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>986</th>\n","      <td>@united really?  Someone called in sick and th...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2577</th>\n","      <td>@united - you delayed our departure by 2 hrs t...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>9120</th>\n","      <td>@USAirways well then that is a horrible flaw i...</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                    text airline_sentiment\n","14424  @AmericanAir redirect my flight without tellin...          negative\n","4108   @united Call customer service and of course th...          negative\n","11786  @USAirways Haha - that will indeed be a great ...          positive\n","3801   @united trade show! Come by both 130 for aweso...           neutral\n","10384  @USAirways Can't stress enough how awful the a...          negative\n","1412   @united  bags left behind because plane overwe...          negative\n","5417   @SouthwestAir Suggestions: tell customers appr...          negative\n","986    @united really?  Someone called in sick and th...          negative\n","2577   @united - you delayed our departure by 2 hrs t...          negative\n","9120   @USAirways well then that is a horrible flaw i...          negative"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"Z-JcvzD4zdGv","executionInfo":{"status":"ok","timestamp":1608646962580,"user_tz":-420,"elapsed":1378,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["X_train, X_test, y_train, y_test = train_test_split(dataset.text, dataset.airline_sentiment, test_size = 0.2, random_state = 42)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"dMjkliSpq2qZ","executionInfo":{"status":"ok","timestamp":1608646966461,"user_tz":-420,"elapsed":913,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# proprocessing data teks\r\n","def review_wordlist(review, remove_stopwords=False):\r\n","    \r\n","    # hapus simbol\r\n","    review_text = re.sub(\"[^a-zA-Z]\",\" \",review)\r\n","    \r\n","    # hapus @\r\n","    review_text = re.sub(\"([^\\s\\w]|_@?)+\",\" \", review_text)\r\n","\r\n","    # konversi ke huruf kecil dan dipisah perkata\r\n","    words = review_text.lower().split()\r\n","\r\n","    # menghapus stopwords\r\n","    if remove_stopwords:\r\n","        stops = set(stopwords.words(\"english\"))     \r\n","        words = [w for w in words if not w in stops]\r\n","    \r\n","    return(words)"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgXzs194r921","executionInfo":{"status":"ok","timestamp":1608646968811,"user_tz":-420,"elapsed":1123,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"60de9c53-f10e-4a2c-82df-28615ff62e8f"},"source":["# download file punctuation and stpwords\r\n","nltk.download('punkt')\r\n","nltk.download('stopwords')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"D3L8IJV5sAJs","executionInfo":{"status":"ok","timestamp":1608646971460,"user_tz":-420,"elapsed":1061,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# word2vec expects a list of lists.\r\n","# Using punkt tokenizer for better splitting of a paragraph into sentences.\r\n","\r\n","import nltk.data\r\n","#nltk.download('popular')\r\n","\r\n","tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxWkV-husCtU","executionInfo":{"status":"ok","timestamp":1608646975014,"user_tz":-420,"elapsed":1375,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# Memisah review per kalimat\r\n","def review_sentences(review, tokenizer, remove_stopwords=False):\r\n","    \r\n","    # melakukan tokenize dengan nltk tokenizer\r\n","    raw_sentences = tokenizer.tokenize(review.strip())\r\n","    sentences = []\r\n","\r\n","    # mengisi array sentences dengan masing - masing review\r\n","    for raw_sentence in raw_sentences:\r\n","        if len(raw_sentence)>0:\r\n","            sentences.append(review_wordlist(raw_sentence, remove_stopwords))\r\n","\r\n","    # list dari list\r\n","    return sentences"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-iOQ9BUsFCs","executionInfo":{"status":"ok","timestamp":1608646979248,"user_tz":-420,"elapsed":1740,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"2c54f916-1634-4939-bcec-5acd706398d3"},"source":["sentences = []\r\n","print(\"Parsing sentences from training set\")\r\n","for review in X_train:\r\n","    sentences += review_sentences(review, tokenizer)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Parsing sentences from training set\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9W17AUWCtsWd","executionInfo":{"status":"ok","timestamp":1608646986109,"user_tz":-420,"elapsed":1066,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"e9cd39fb-0ca5-4210-f254-91ec62ed1a11"},"source":["print(\"List dari lists. Cek tipe data : \", type(sentences), \" of \", type(sentences[0]))\r\n","# print(sentences)\r\n","print(sentences[105])\r\n","print(len(sentences))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["List dari lists. Cek tipe data :  <class 'list'>  of  <class 'list'>\n","['united', 'darquenloveli', 'we', 'regret', 'to', 'hear', 'this']\n","23490\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g9I0x6EswNEx","executionInfo":{"status":"ok","timestamp":1608645760348,"user_tz":-420,"elapsed":1272,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["best_score = []\r\n","best_parameter = []"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"gSS0ZaLuwPkN","executionInfo":{"status":"ok","timestamp":1608647409871,"user_tz":-420,"elapsed":1164,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["# parameter yang akan dioptimasi\r\n","parm_dict = {\r\n","    'workers' : (4,),\r\n","    'size' : (300, 350, 400, 450, 500, 550, 600),\r\n","    'min_count' : (40,),\r\n","    'window' : (10,)\r\n","}\r\n","\r\n","# melakukan x, dengan metode y, untuk z \r\n","# optimization of feature dimension on word embedding based on vector size using grid search for sentimen analysis\r\n","\r\n","def cust_param_search(parm_dict):\r\n","\r\n","    score_best, parm_best = 0,()\r\n","    workers, size, min_count, window = [tup for k,tup in parm_dict.items()] # Individual parm tuples\r\n","    parm_combo = list(itertools.product(workers, size, min_count, window)) # Create all combinations\r\n","    \r\n","    print('\\n==============================================================')\r\n","    print('PARAMETER')\r\n","    print('==============================================================')\r\n","    print(f'Total kombinasi parameter   : {len(parm_combo)}')\r\n","    print(f'Semua kombinasi parameter   : {parm_combo}')\r\n","\r\n","    # Grid search\r\n","    i = 1\r\n","    for parms in parm_combo:\r\n","\r\n","        print('\\n==============================================================')\r\n","        print(f'{i}.\\t Parameter : {parms}')\r\n","        print('==============================================================')\r\n","        \r\n","        w, s, m, wi = parms\r\n","        \r\n","        # =================================================================================\r\n","        # word2vec mulai disini\r\n","        # =================================================================================\r\n","        \r\n","        # word2vec model\r\n","        model = word2vec.Word2Vec(workers = w, \r\n","                              size = s, \r\n","                              min_count = m, \r\n","                              window = wi)\r\n","        model.build_vocab(sentences)\r\n","\r\n","        # training model word2vec (CBOW, karena parameter 'sg' menggunakan nilai default)\r\n","        print('\\n==============================================================')\r\n","        print(\"Training model Word2Vec ...\")\r\n","        print('==============================================================')\r\n","        model.train(sentences = sentences, total_examples = len(sentences), epochs = 5)\r\n","\r\n","        # Function to average all word vectors in a paragraph\r\n","        def featureVecMethod(words, model, num_features):\r\n","            # Pre-initialising empty numpy array for speed\r\n","            featureVec = np.zeros(s,dtype=\"float32\")\r\n","            nwords = 0\r\n","            \r\n","            #Converting Index2Word which is a list to a set for better speed in the execution.\r\n","            index2word_set = set(model.wv.index2word)\r\n","            \r\n","            for word in  words:\r\n","                if word in index2word_set:\r\n","                    nwords = nwords + 1\r\n","                    featureVec = np.add(featureVec,model[word])\r\n","            \r\n","            # Dividing the result by number of words to get average\r\n","            featureVec = np.divide(featureVec, nwords)\r\n","            return featureVec\r\n","\r\n","        # Function for calculating the average feature vector\r\n","        def getAvgFeatureVecs(reviews, model, num_features):\r\n","            counter = 0\r\n","            reviewFeatureVecs = np.zeros((len(reviews),s),dtype=\"float32\")\r\n","            for review in reviews:\r\n","                # Printing a status message every 1000th review\r\n","                if counter%1000 == 0:\r\n","                    print(\"Review %d of %d\"%(counter,len(reviews)))\r\n","                    \r\n","                reviewFeatureVecs[counter] = featureVecMethod(review, model, s)\r\n","                counter = counter+1\r\n","                \r\n","            return reviewFeatureVecs\r\n","\r\n","        # Calculating average feature vector (mendapatkan vektor training set)\r\n","        clean_train_reviews = []\r\n","        for review in X_train:\r\n","            clean_train_reviews.append(review_wordlist(review, remove_stopwords=True))\r\n","            \r\n","        trainDataVecs = getAvgFeatureVecs(clean_train_reviews, model, s)\r\n","\r\n","        # Calculating average feature vactors (mendapatkan vektor test set)     \r\n","        clean_test_reviews = []\r\n","        for review in X_test:\r\n","            clean_test_reviews.append(review_wordlist(review,remove_stopwords=True))\r\n","            \r\n","        testDataVecs = getAvgFeatureVecs(clean_test_reviews, model, s)\r\n","\r\n","        # tujuan masing-masing model word2vec, untuk mendapatkan 'trainDataVecs' dan 'testDataVecs' \r\n","        # untuk diolah lebih lanjut di classifier\r\n","        \r\n","        # =================================================================================\r\n","        # word2vec berakhir disini\r\n","        # =================================================================================\r\n","\r\n","        print('\\n==============================================================')\r\n","        print('Sentiment Analysis Process ...')\r\n","        print('==============================================================')\r\n","        # Memanggil classifier\r\n","        score, report = classification_model(trainDataVecs, testDataVecs, y_train, y_test)\r\n","\r\n","        # temporary print\r\n","        print('\\n==============================================================')\r\n","        print(f'Hasil Test Parameter ke - {i}')\r\n","        print(f'Parameter  => {parms}')\r\n","        print(f'Accuracy   => {score}')\r\n","        print(f'Classification Report => \\n {report}')\r\n","\r\n","        best_score.append(score)\r\n","        best_parameter.append(parms)\r\n","        \r\n","        if score > score_best:\r\n","            score_best = score\r\n","            parm_best = parms\r\n","        \r\n","        i = i + 1\r\n","    \r\n","    print('\\n==============================================================')\r\n","    print(f'Best Parameter  => {parm_best}')\r\n","    print(f'Accuracy   => {score_best}')\r\n","    print('==============================================================')"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8L1b2f4wczL","executionInfo":{"status":"ok","timestamp":1608647150609,"user_tz":-420,"elapsed":1172,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}}},"source":["def classification_model(train_feature_vec, test_feature_vec, train_sentiment, test_sentiment):\r\n","\r\n","    # Model/classifier yang dipakai bebas\r\n","    # Fit random forest classifier ke data training\r\n","    forest = RandomForestClassifier(n_estimators = 100)    \r\n","    forest = forest.fit(train_feature_vec, train_sentiment) \r\n","\r\n","    # Prediksi nilai sentiment untuk test data \r\n","    predicted = forest.predict(test_feature_vec)\r\n","\r\n","    # akurasi\r\n","    accuracy = accuracy_score(test_sentiment, predicted)\r\n","    report = classification_report(test_sentiment, predicted, digits = 5)\r\n","    \r\n","    return accuracy, report"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dndjPQtCwhWl","executionInfo":{"status":"ok","timestamp":1608647685505,"user_tz":-420,"elapsed":261808,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"ca98d379-d6ea-46ae-e4dc-d33a0ddb12d6"},"source":["# test drive ma men (estimasi running : 21.30)\r\n","cust_param_search(parm_dict)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["\n","==============================================================\n","PARAMETER\n","==============================================================\n","Total kombinasi parameter   : 7\n","Semua kombinasi parameter   : [(4, 300, 40, 10), (4, 350, 40, 10), (4, 400, 40, 10), (4, 450, 40, 10), (4, 500, 40, 10), (4, 550, 40, 10), (4, 600, 40, 10)]\n","\n","==============================================================\n","1.\t Parameter : (4, 300, 40, 10) \n","\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 11712\n","Review 1000 of 11712\n","Review 2000 of 11712\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["Review 3000 of 11712\n","Review 4000 of 11712\n","Review 5000 of 11712\n","Review 6000 of 11712\n","Review 7000 of 11712\n","Review 8000 of 11712\n","Review 9000 of 11712\n","Review 10000 of 11712\n","Review 11000 of 11712\n","Review 0 of 2928\n","Review 1000 of 2928\n","Review 2000 of 2928\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n","\n","==============================================================\n","Hasil Test Parameter ke - 1\n","Parameter  => (4, 300, 40, 10)\n","Accuracy   => 0.719603825136612\n","Classification Report => \n","               precision    recall  f1-score   support\n","\n","    negative    0.75112   0.91608   0.82544      1835\n","     neutral    0.55714   0.37440   0.44785       625\n","    positive    0.71111   0.41026   0.52033       468\n","\n","    accuracy                        0.71960      2928\n","   macro avg    0.67312   0.56691   0.59787      2928\n","weighted avg    0.70332   0.71960   0.69607      2928\n","\n","\n","==============================================================\n","2.\t Parameter : (4, 350, 40, 10) \n","\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 11712\n","Review 1000 of 11712\n","Review 2000 of 11712\n","Review 3000 of 11712\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["Review 4000 of 11712\n","Review 5000 of 11712\n","Review 6000 of 11712\n","Review 7000 of 11712\n","Review 8000 of 11712\n","Review 9000 of 11712\n","Review 10000 of 11712\n","Review 11000 of 11712\n","Review 0 of 2928\n","Review 1000 of 2928\n","Review 2000 of 2928\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n","\n","==============================================================\n","Hasil Test Parameter ke - 2\n","Parameter  => (4, 350, 40, 10)\n","Accuracy   => 0.7172131147540983\n","Classification Report => \n","               precision    recall  f1-score   support\n","\n","    negative    0.75600   0.91008   0.82591      1835\n","     neutral    0.53756   0.36640   0.43578       625\n","    positive    0.68601   0.42949   0.52825       468\n","\n","    accuracy                        0.71721      2928\n","   macro avg    0.65985   0.56866   0.59665      2928\n","weighted avg    0.69818   0.71721   0.69506      2928\n","\n","\n","==============================================================\n","3.\t Parameter : (4, 400, 40, 10) \n","\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 11712\n","Review 1000 of 11712\n","Review 2000 of 11712\n","Review 3000 of 11712\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["Review 4000 of 11712\n","Review 5000 of 11712\n","Review 6000 of 11712\n","Review 7000 of 11712\n","Review 8000 of 11712\n","Review 9000 of 11712\n","Review 10000 of 11712\n","Review 11000 of 11712\n","Review 0 of 2928\n","Review 1000 of 2928\n","Review 2000 of 2928\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n","\n","==============================================================\n","Hasil Test Parameter ke - 3\n","Parameter  => (4, 400, 40, 10)\n","Accuracy   => 0.7161885245901639\n","Classification Report => \n","               precision    recall  f1-score   support\n","\n","    negative    0.75248   0.90954   0.82359      1835\n","     neutral    0.54779   0.37600   0.44592       625\n","    positive    0.68683   0.41239   0.51535       468\n","\n","    accuracy                        0.71619      2928\n","   macro avg    0.66237   0.56598   0.59495      2928\n","weighted avg    0.69829   0.71619   0.69371      2928\n","\n","\n","==============================================================\n","4.\t Parameter : (4, 450, 40, 10) \n","\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 11712\n","Review 1000 of 11712\n","Review 2000 of 11712\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["Review 3000 of 11712\n","Review 4000 of 11712\n","Review 5000 of 11712\n","Review 6000 of 11712\n","Review 7000 of 11712\n","Review 8000 of 11712\n","Review 9000 of 11712\n","Review 10000 of 11712\n","Review 11000 of 11712\n","Review 0 of 2928\n","Review 1000 of 2928\n","Review 2000 of 2928\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n","\n","==============================================================\n","Hasil Test Parameter ke - 4\n","Parameter  => (4, 450, 40, 10)\n","Accuracy   => 0.7110655737704918\n","Classification Report => \n","               precision    recall  f1-score   support\n","\n","    negative    0.74498   0.90899   0.81885      1835\n","     neutral    0.53810   0.36160   0.43254       625\n","    positive    0.69888   0.40171   0.51018       468\n","\n","    accuracy                        0.71107      2928\n","   macro avg    0.66065   0.55743   0.58719      2928\n","weighted avg    0.69345   0.71107   0.68705      2928\n","\n","\n","==============================================================\n","5.\t Parameter : (4, 500, 40, 10) \n","\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 11712\n","Review 1000 of 11712\n","Review 2000 of 11712\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["Review 3000 of 11712\n","Review 4000 of 11712\n","Review 5000 of 11712\n","Review 6000 of 11712\n","Review 7000 of 11712\n","Review 8000 of 11712\n","Review 9000 of 11712\n","Review 10000 of 11712\n","Review 11000 of 11712\n","Review 0 of 2928\n","Review 1000 of 2928\n","Review 2000 of 2928\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n","\n","==============================================================\n","Hasil Test Parameter ke - 5\n","Parameter  => (4, 500, 40, 10)\n","Accuracy   => 0.717896174863388\n","Classification Report => \n","               precision    recall  f1-score   support\n","\n","    negative    0.75157   0.91172   0.82393      1835\n","     neutral    0.55875   0.37280   0.44722       625\n","    positive    0.68772   0.41880   0.52058       468\n","\n","    accuracy                        0.71790      2928\n","   macro avg    0.66601   0.56777   0.59725      2928\n","weighted avg    0.70021   0.71790   0.69504      2928\n","\n","\n","==============================================================\n","6.\t Parameter : (4, 550, 40, 10) \n","\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 11712\n","Review 1000 of 11712\n","Review 2000 of 11712\n","Review 3000 of 11712\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["Review 4000 of 11712\n","Review 5000 of 11712\n","Review 6000 of 11712\n","Review 7000 of 11712\n","Review 8000 of 11712\n","Review 9000 of 11712\n","Review 10000 of 11712\n","Review 11000 of 11712\n","Review 0 of 2928\n","Review 1000 of 2928\n","Review 2000 of 2928\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n","\n","==============================================================\n","Hasil Test Parameter ke - 6\n","Parameter  => (4, 550, 40, 10)\n","Accuracy   => 0.7141393442622951\n","Classification Report => \n","               precision    recall  f1-score   support\n","\n","    negative    0.75056   0.91008   0.82266      1835\n","     neutral    0.53349   0.36960   0.43667       625\n","    positive    0.70370   0.40598   0.51491       468\n","\n","    accuracy                        0.71414      2928\n","   macro avg    0.66258   0.56189   0.59141      2928\n","weighted avg    0.69674   0.71414   0.69108      2928\n","\n","\n","==============================================================\n","7.\t Parameter : (4, 600, 40, 10) \n","\n","==============================================================\n","\n","==============================================================\n","Training model Word2Vec ...\n","==============================================================\n","Review 0 of 11712\n","Review 1000 of 11712\n","Review 2000 of 11712\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"],"name":"stderr"},{"output_type":"stream","text":["Review 3000 of 11712\n","Review 4000 of 11712\n","Review 5000 of 11712\n","Review 6000 of 11712\n","Review 7000 of 11712\n","Review 8000 of 11712\n","Review 9000 of 11712\n","Review 10000 of 11712\n","Review 11000 of 11712\n","Review 0 of 2928\n","Review 1000 of 2928\n","Review 2000 of 2928\n","\n","==============================================================\n","Sentiment Analysis Process ...\n","==============================================================\n","\n","==============================================================\n","Hasil Test Parameter ke - 7\n","Parameter  => (4, 600, 40, 10)\n","Accuracy   => 0.7155054644808743\n","Classification Report => \n","               precision    recall  f1-score   support\n","\n","    negative    0.74877   0.91117   0.82203      1835\n","     neutral    0.54916   0.36640   0.43954       625\n","    positive    0.69784   0.41453   0.52011       468\n","\n","    accuracy                        0.71551      2928\n","   macro avg    0.66526   0.56403   0.59389      2928\n","weighted avg    0.69802   0.71551   0.69212      2928\n","\n","\n","==============================================================\n","Best Parameter  => (4, 300, 40, 10)\n","Accuracy   => 0.719603825136612\n","==============================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZhew0Li39gV","executionInfo":{"status":"ok","timestamp":1608648039712,"user_tz":-420,"elapsed":1068,"user":{"displayName":"Adi Setyo Nugroho","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0Q_nMq9AllChA8jD-rL5hF6aCxQglVjBPvIYk3A=s64","userId":"06110464055894724226"}},"outputId":"b9dc4f21-cca6-4014-ba95-acb1cba96daf"},"source":["print(best_score)\r\n","print(best_parameter)"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[0.7134562841530054, 0.7151639344262295, 0.7175546448087432, 0.717896174863388, 0.7182377049180327, 0.719603825136612, 0.7172131147540983, 0.7161885245901639, 0.7110655737704918, 0.717896174863388, 0.7141393442622951, 0.7155054644808743]\n","[(4, 300, 40, 10), (4, 350, 40, 10), (4, 400, 40, 10), (4, 450, 40, 10), (4, 500, 40, 10), (4, 300, 40, 10), (4, 350, 40, 10), (4, 400, 40, 10), (4, 450, 40, 10), (4, 500, 40, 10), (4, 550, 40, 10), (4, 600, 40, 10)]\n"],"name":"stdout"}]}]}